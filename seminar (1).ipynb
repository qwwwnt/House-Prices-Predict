{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-05T11:57:43.110286Z",
     "iopub.status.busy": "2024-04-05T11:57:43.110286Z",
     "iopub.status.idle": "2024-04-05T11:58:24.893715Z",
     "shell.execute_reply": "2024-04-05T11:58:24.893715Z",
     "shell.execute_reply.started": "2024-04-05T11:57:43.110286Z"
    },
    "id": "zriTdjauH8iQ",
    "outputId": "e25d0f3f-2879-4d80-8cad-f949cf5b8453"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\zenfo\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\zenfo\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\zenfo\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\zenfo\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\zenfo\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\zenfo\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers huggingface_hub\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQiRPWWHlSgv"
   },
   "source": [
    "### Using pre-trained transformers (2 points)\n",
    "_for fun and profit_\n",
    "\n",
    "There are many toolkits that let you access pre-trained transformer models, but the most powerful and convenient by far is [`huggingface/transformers`](https://github.com/huggingface/transformers). In this week's practice, you'll learn how to download, apply and modify pre-trained transformers for a range of tasks. Buckle up, we're going in!\n",
    "\n",
    "\n",
    "__Pipelines:__ if all you want is to apply a pre-trained model, you can do that in one line of code using pipeline. Huggingface/transformers has a selection of pre-configured pipelines for masked language modelling, sentiment classification, question aswering, etc. ([see full list here](https://huggingface.co/transformers/main_classes/pipelines.html))\n",
    "\n",
    "A typical pipeline includes:\n",
    "* pre-processing, e.g. tokenization, subword segmentation\n",
    "* a backbone model, e.g. bert finetuned for classification\n",
    "* output post-processing\n",
    "\n",
    "Let's see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162,
     "referenced_widgets": [
      "e85584c419aa445285eecb482778c7ba",
      "5694548560b548dabed4b111766da60e",
      "7fceb5ec7dec415a9dfcd4261aeb4a3d",
      "1fd2361180bd49aa8e2012a5e379d0c1",
      "77441a81d25c40819ae5af99ad70f3c8",
      "48c3bc239f16407bbba2d36ac6e5aaae",
      "5c87b856ffeb4c1dbf2d4637065d26ef",
      "fbbe93e1d4a5493782b7a246f3cb1760",
      "c3e31f6d90a84af08ee33023be184849",
      "6099e17176dd4eef829ac7c45badc9e2",
      "7ea9a125c76543419007fd5083ed63cd",
      "b2786e8af69e490cba5048fca7a0a51e",
      "f07e54fd856f4efc99bedb44abcece1b",
      "e0d2ca01fd7042a88a5493323a61409c",
      "e07d888d412d43f8ac4cc5285de07772",
      "15227ca6cc5a4d219e0113da09926da4",
      "cf83aaa31a1a47419db2127456beae69",
      "1e463fce356b46859493cbd975163ef1",
      "4ecb5a9efc3c42dd8faf4af9424ad5cf",
      "3af4702b95484b8cabd891b18ffc71b1",
      "e9210c257b8a4091b86123271c8a5486",
      "7eb0bf256b8d4975b0615aa96f00bbe1",
      "fc132bfb7d6447ad9900af7b80806aa1",
      "ab6d124394214415a2580983c88bbb11",
      "8578b4d2279f40dc846fcdfc2df55742",
      "7213248ebe1f4e28a00a93eb33169170",
      "b1497c0d7c3b4c04a91302a2cbc96db1",
      "60e971374e5448d08e9698a5594ff60a",
      "6c8113bb76024debaf3256431cbefe35",
      "73d8ad019f044a6998e81273a922745a",
      "a445a35355424cb0b4c7abf3d4e6f32d",
      "d71a81e25f5b4f88b8361c62e2ab9f44",
      "4f084bbe71bb433ba0e7ee50fccb71cc",
      "5cff2bc12fec494e9e19b8a956186df6",
      "787781c894bd46c6990f2513d9f2c79c",
      "3f4eae6f79054676976f87b9524c4cf5",
      "237d34743ee64428a9d22ee51e0423f3",
      "b095428dcb8a4408854f854de54d5692",
      "1b76512711884ffb81d3c3505b8fd137",
      "2f53a3d1d0f44192beeb6ed8d40e762f",
      "1b194af3033342b0b04dc12b3e055ff2",
      "391b8f44109544328617fbc3a3c3b9fc",
      "6f36db95f6fb4b4687c7130fc23c4348",
      "82a35a7ae5e441a1b66534a3eab5e765"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-04-05T12:22:20.913244Z",
     "iopub.status.busy": "2024-04-05T12:22:20.905265Z",
     "iopub.status.idle": "2024-04-05T12:23:06.515994Z",
     "shell.execute_reply": "2024-04-05T12:23:06.514997Z",
     "shell.execute_reply.started": "2024-04-05T12:22:20.912247Z"
    },
    "id": "rP1KFtvLlJHR",
    "outputId": "f4e9f426-6445-4d69-b7b7-dd083d7bdebf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3fbe327a0a64372868617bc2aa49af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zenfo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\zenfo\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e05a66b3ac54cf1ba8a5f9b433b24a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c752a3e34c4cd0b758acbb5a1a12f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd5a4ccb6db4899874d9a4c43bdb57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998860359191895}]\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "classifier = transformers.pipeline('sentiment-analysis', model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "print(classifier(\"BERT is amazing!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T12:43:04.564172Z",
     "iopub.status.busy": "2024-04-06T12:43:04.563176Z",
     "iopub.status.idle": "2024-04-06T12:43:04.598079Z",
     "shell.execute_reply": "2024-04-06T12:43:04.598079Z",
     "shell.execute_reply.started": "2024-04-06T12:43:04.564172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEGATIVE'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('pidarasi blyat')[0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T12:43:34.231753Z",
     "iopub.status.busy": "2024-04-06T12:43:34.231753Z",
     "iopub.status.idle": "2024-04-06T12:43:34.380353Z",
     "shell.execute_reply": "2024-04-06T12:43:34.380353Z",
     "shell.execute_reply.started": "2024-04-06T12:43:34.231753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997355341911316},\n",
       " {'label': 'NEGATIVE', 'score': 0.6957702040672302},\n",
       " {'label': 'POSITIVE', 'score': 0.9950939416885376},\n",
       " {'label': 'POSITIVE', 'score': 0.9998761415481567}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(list(data.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T12:40:22.952315Z",
     "iopub.status.busy": "2024-04-06T12:40:22.952315Z",
     "iopub.status.idle": "2024-04-06T12:40:22.976261Z",
     "shell.execute_reply": "2024-04-06T12:40:22.975250Z",
     "shell.execute_reply.started": "2024-04-06T12:40:22.952315Z"
    }
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "data = {\n",
    "    'arryn': 'As High as Honor.',\n",
    "    'baratheon': 'Ours is the fury.',\n",
    "    'stark': 'Winter is coming.',\n",
    "    'tyrell': 'Growing strong.'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T12:43:44.471398Z",
     "iopub.status.busy": "2024-04-06T12:43:44.470401Z",
     "iopub.status.idle": "2024-04-06T12:43:44.592074Z",
     "shell.execute_reply": "2024-04-06T12:43:44.591077Z",
     "shell.execute_reply.started": "2024-04-06T12:43:44.471398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arryn': True, 'baratheon': False, 'stark': True, 'tyrell': True}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: True if classifier(v)[0]['label'] == 'POSITIVE' else False for k, v in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T12:42:44.812205Z",
     "iopub.status.busy": "2024-04-06T12:42:44.812205Z",
     "iopub.status.idle": "2024-04-06T12:42:44.905954Z",
     "shell.execute_reply": "2024-04-06T12:42:44.904956Z",
     "shell.execute_reply.started": "2024-04-06T12:42:44.812205Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m {k: classifier(v)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()}\n",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m {k: \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "{k: classifier(v)['label'] for k, v in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T12:44:17.198413Z",
     "iopub.status.busy": "2024-04-06T12:44:17.197416Z",
     "iopub.status.idle": "2024-04-06T12:44:17.317096Z",
     "shell.execute_reply": "2024-04-06T12:44:17.316098Z",
     "shell.execute_reply.started": "2024-04-06T12:44:17.198413Z"
    },
    "id": "nYUNuyXMn5l9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # YOUR CODE: predict sentiment for each noble house and create outputs dict\n",
    "\n",
    "\n",
    "# {for data.items()]\n",
    "# dict()\n",
    "\n",
    "# outputs = <YOUR CODE: dict (house name) : True if positive, False if negative>\n",
    "\n",
    "outputs = {k: True if classifier(v)[0]['label'] == 'POSITIVE' else False for k, v in data.items()}\n",
    "\n",
    "assert sum(outputs.values()) == 3 and outputs[base64.decodebytes(b'YmFyYXRoZW9u\\n').decode()] == False\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRDhIH-XpSNo"
   },
   "source": [
    "You can also access vanilla Masked Language Model that was trained to predict masked words. Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T12:45:13.192420Z",
     "iopub.status.busy": "2024-04-06T12:45:13.191430Z",
     "iopub.status.idle": "2024-04-06T12:45:34.127458Z",
     "shell.execute_reply": "2024-04-06T12:45:34.126508Z",
     "shell.execute_reply.started": "2024-04-06T12:45:13.192420Z"
    },
    "id": "pa-8noIllRbZ"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1495f0f24a4145c4966f00d4f5faef73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zenfo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\zenfo\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd63b26ff0904a748fff0e3159a849e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e492ada3f70547a68febde81e8a96527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2578f3499a83461a8104f379af092d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd9a6e93daa466cbd66a8065fef1902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P=0.99719 donald trump is the president of the united states.\n",
      "P=0.00024 donald duck is the president of the united states.\n",
      "P=0.00022 donald ross is the president of the united states.\n",
      "P=0.00020 donald johnson is the president of the united states.\n",
      "P=0.00018 donald wilson is the president of the united states.\n"
     ]
    }
   ],
   "source": [
    "mlm_model = transformers.pipeline('fill-mask', model=\"bert-base-uncased\")\n",
    "MASK = mlm_model.tokenizer.mask_token\n",
    "\n",
    "for hypo in mlm_model(f\"Donald {MASK} is the president of the united states.\"):\n",
    "  print(f\"P={hypo['score']:.5f}\", hypo['sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T12:55:50.534925Z",
     "iopub.status.busy": "2024-04-06T12:55:50.534925Z",
     "iopub.status.idle": "2024-04-06T12:55:50.541907Z",
     "shell.execute_reply": "2024-04-06T12:55:50.540909Z",
     "shell.execute_reply.started": "2024-04-06T12:55:50.534925Z"
    },
    "id": "9NxeG1Y5pwX1"
   },
   "outputs": [],
   "source": [
    "# Your turn: use bert to recall what year was the Soviet Union founded in\n",
    "# mlm_model('the Soviet Union was founded in {}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T12:58:06.677965Z",
     "iopub.status.busy": "2024-04-06T12:58:06.676968Z",
     "iopub.status.idle": "2024-04-06T12:58:06.794651Z",
     "shell.execute_reply": "2024-04-06T12:58:06.793655Z",
     "shell.execute_reply.started": "2024-04-06T12:58:06.677965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.037022415548563004,\n",
       "  'token': 2462,\n",
       "  'token_str': 'ii',\n",
       "  'sequence': 'the soviet union was founded in year ii.'},\n",
       " {'score': 0.030535703524947166,\n",
       "  'token': 3386,\n",
       "  'token_str': '1945',\n",
       "  'sequence': 'the soviet union was founded in year 1945.'},\n",
       " {'score': 0.027637531980872154,\n",
       "  'token': 4585,\n",
       "  'token_str': '1917',\n",
       "  'sequence': 'the soviet union was founded in year 1917.'},\n",
       " {'score': 0.023243645206093788,\n",
       "  'token': 4271,\n",
       "  'token_str': '1918',\n",
       "  'sequence': 'the soviet union was founded in year 1918.'},\n",
       " {'score': 0.017537804320454597,\n",
       "  'token': 4085,\n",
       "  'token_str': '1949',\n",
       "  'sequence': 'the soviet union was founded in year 1949.'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_model(f'the Soviet Union was founded in year {MASK}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T12:55:53.854877Z",
     "iopub.status.busy": "2024-04-06T12:55:53.854877Z",
     "iopub.status.idle": "2024-04-06T12:55:54.626898Z",
     "shell.execute_reply": "2024-04-06T12:55:54.579026Z",
     "shell.execute_reply.started": "2024-04-06T12:55:53.854877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P=0.90567 the soviet union was founded in that year.\n",
      "P=0.08825 the soviet union was founded in this year.\n",
      "P=0.00178 the soviet union was founded in the year.\n",
      "P=0.00097 the soviet union was founded in same year.\n",
      "P=0.00081 the soviet union was founded in one year.\n"
     ]
    }
   ],
   "source": [
    "for hypo in mlm_model(f\"the Soviet Union was founded in  {MASK} year.\"):\n",
    "  print(f\"P={hypo['score']:.5f}\", hypo['sequence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJxRFzCSq903"
   },
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Huggingface offers hundreds of pre-trained models that specialize on different tasks. You can quickly find the model you need using [this list](https://huggingface.co/models).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T13:25:43.136993Z",
     "iopub.status.busy": "2024-04-06T13:25:43.121037Z",
     "iopub.status.idle": "2024-04-06T13:26:45.249014Z",
     "shell.execute_reply": "2024-04-06T13:26:45.236047Z",
     "shell.execute_reply.started": "2024-04-06T13:25:43.136993Z"
    },
    "id": "HRux8Qp2hkXr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79384e49421438abd5040eb7195431d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zenfo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\zenfo\\.cache\\huggingface\\hub\\models--dbmdz--bert-large-cased-finetuned-conll03-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806ca4d315644f23873dc560a2b2442b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e54330092248ff9978087673ec6ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a7999fad84490cbc35c0f83fe90d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"\"\"Almost two-thirds of the 1.5 million people who viewed this liveblog had Googled to discover\n",
    " the latest on the Rosetta mission. They were treated to this detailed account by the Guardian’s science editor,\n",
    " Ian Sample, and astronomy writer Stuart Clark of the moment scientists landed a robotic spacecraft on a comet\n",
    " for the first time in history, and the delirious reaction it provoked at their headquarters in Germany.\n",
    "  “We are there. We are sitting on the surface. Philae is talking to us,” said one scientist.\n",
    "\"\"\"\n",
    "\n",
    "# Task: create a pipeline for named entity recognition, use task name 'ner' and search for the right model in the list\n",
    "ner_model = transformers.pipeline('ner')\n",
    "\n",
    "named_entities = ner_model(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T13:26:45.281926Z",
     "iopub.status.busy": "2024-04-06T13:26:45.278934Z",
     "iopub.status.idle": "2024-04-06T13:26:45.348747Z",
     "shell.execute_reply": "2024-04-06T13:26:45.344757Z",
     "shell.execute_reply.started": "2024-04-06T13:26:45.281926Z"
    },
    "id": "hf57MRzSiSON"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT: [{'entity': 'I-MISC', 'score': 0.88031095, 'index': 19, 'word': 'Google', 'start': 73, 'end': 79}, {'entity': 'I-MISC', 'score': 0.90050775, 'index': 27, 'word': 'Rose', 'start': 112, 'end': 116}, {'entity': 'I-MISC', 'score': 0.95096284, 'index': 28, 'word': '##tta', 'start': 116, 'end': 119}, {'entity': 'I-ORG', 'score': 0.99925345, 'index': 40, 'word': 'Guardian', 'start': 179, 'end': 187}, {'entity': 'I-PER', 'score': 0.999201, 'index': 46, 'word': 'Ian', 'start': 207, 'end': 210}, {'entity': 'I-PER', 'score': 0.9994999, 'index': 47, 'word': 'Sam', 'start': 211, 'end': 214}, {'entity': 'I-PER', 'score': 0.99649787, 'index': 48, 'word': '##ple', 'start': 214, 'end': 217}, {'entity': 'I-PER', 'score': 0.9991856, 'index': 53, 'word': 'Stuart', 'start': 240, 'end': 246}, {'entity': 'I-PER', 'score': 0.99964833, 'index': 54, 'word': 'Clark', 'start': 247, 'end': 252}, {'entity': 'I-LOC', 'score': 0.9998211, 'index': 85, 'word': 'Germany', 'start': 413, 'end': 420}, {'entity': 'I-PER', 'score': 0.6295695, 'index': 99, 'word': 'Phil', 'start': 470, 'end': 474}, {'entity': 'I-PER', 'score': 0.8340382, 'index': 100, 'word': '##ae', 'start': 474, 'end': 476}]\n",
      "All tests passed\n"
     ]
    }
   ],
   "source": [
    "print('OUTPUT:', named_entities)\n",
    "word_to_entity = {item['word']: item['entity'] for item in named_entities}\n",
    "assert 'org' in word_to_entity.get('Guardian').lower() and 'per' in word_to_entity.get('Stuart').lower()\n",
    "print(\"All tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T13:27:58.420153Z",
     "iopub.status.busy": "2024-04-06T13:27:58.419155Z",
     "iopub.status.idle": "2024-04-06T13:27:58.450077Z",
     "shell.execute_reply": "2024-04-06T13:27:58.449076Z",
     "shell.execute_reply.started": "2024-04-06T13:27:58.420153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Google': 'I-MISC',\n",
       " 'Rose': 'I-MISC',\n",
       " '##tta': 'I-MISC',\n",
       " 'Guardian': 'I-ORG',\n",
       " 'Ian': 'I-PER',\n",
       " 'Sam': 'I-PER',\n",
       " '##ple': 'I-PER',\n",
       " 'Stuart': 'I-PER',\n",
       " 'Clark': 'I-PER',\n",
       " 'Germany': 'I-LOC',\n",
       " 'Phil': 'I-PER',\n",
       " '##ae': 'I-PER'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULMownz6sP9n"
   },
   "source": [
    "### The building blocks of a pipeline\n",
    "\n",
    "Huggingface also allows you to access its pipelines on a lower level. There are two main abstractions for you:\n",
    "* `Tokenizer` - converts from strings to token ids and back\n",
    "* `Model` - a pytorch `nn.Module` with pre-trained weights\n",
    "\n",
    "You can use such models as part of your regular pytorch code: insert is as a layer in your model, apply it to a batch of data, backpropagate, optimize, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T13:37:54.642239Z",
     "iopub.status.busy": "2024-04-06T13:37:54.642239Z",
     "iopub.status.idle": "2024-04-06T13:37:56.582809Z",
     "shell.execute_reply": "2024-04-06T13:37:56.581812Z",
     "shell.execute_reply.started": "2024-04-06T13:37:54.642239Z"
    },
    "id": "KMJbV0QVsO0Q"
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = transformers.AutoModel.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T13:37:57.383211Z",
     "iopub.status.busy": "2024-04-06T13:37:57.382214Z",
     "iopub.status.idle": "2024-04-06T13:37:57.458242Z",
     "shell.execute_reply": "2024-04-06T13:37:57.456636Z",
     "shell.execute_reply.started": "2024-04-06T13:37:57.383211Z"
    },
    "id": "ZgSPHKPRxG6U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids tensor([[ 101, 5355, 1010, 1045, 2572, 2115, 2269, 1012,  102,    0,    0,    0,\n",
      "            0,    0,    0],\n",
      "        [ 101, 2166, 2003, 2054, 6433, 2043, 2017, 1005, 2128, 5697, 2437, 2060,\n",
      "         3488, 1012,  102]])\n",
      "token_type_ids tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "attention_mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "Detokenized:\n",
      "[CLS] luke, i am your father. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS] life is what happens when you're busy making other plans. [SEP]\n"
     ]
    }
   ],
   "source": [
    "lines = [\n",
    "    \"Luke, I am your father.\",\n",
    "    \"Life is what happens when you're busy making other plans.\",\n",
    "    ]\n",
    "\n",
    "# tokenize a batch of inputs. \"pt\" means [p]y[t]orch tensors\n",
    "tokens_info = tokenizer(lines, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "for key in tokens_info:\n",
    "    print(key, tokens_info[key])\n",
    "\n",
    "print(\"Detokenized:\")\n",
    "for i in range(2):\n",
    "    print(tokenizer.decode(tokens_info['input_ids'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T13:38:02.806175Z",
     "iopub.status.busy": "2024-04-06T13:38:02.806175Z",
     "iopub.status.idle": "2024-04-06T13:38:02.997664Z",
     "shell.execute_reply": "2024-04-06T13:38:02.996665Z",
     "shell.execute_reply.started": "2024-04-06T13:38:02.806175Z"
    },
    "id": "MJkbHxERyfL4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8854, -0.4722, -0.9392,  ..., -0.8081, -0.6955,  0.8748],\n",
      "        [-0.9297, -0.5161, -0.9334,  ..., -0.9017, -0.7492,  0.9201]])\n"
     ]
    }
   ],
   "source": [
    "# You can now apply the model to get embeddings\n",
    "with torch.no_grad():\n",
    "    out = model(**tokens_info)\n",
    "\n",
    "print(out['pooler_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T14:53:32.769723Z",
     "iopub.status.busy": "2024-04-06T14:53:32.754763Z",
     "iopub.status.idle": "2024-04-06T14:53:32.811612Z",
     "shell.execute_reply": "2024-04-06T14:53:32.808620Z",
     "shell.execute_reply.started": "2024-04-06T14:53:32.769723Z"
    }
   },
   "outputs": [],
   "source": [
    "# out['pooler_output'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Vij7Gc1wOaq"
   },
   "source": [
    "Transformers knowledge hub: https://huggingface.co/transformers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwmTTyjUGqol"
   },
   "source": [
    "### Build-a-transformer (2 points)\n",
    "\n",
    "In this section, you will implement a transformer language model layer by layer, then use it to generate (hopefully) coherent text.\n",
    "\n",
    "To understand how these layers work, please check out our guide to transformers from [nlp course for you -> transformers](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html#transformer_intro).\n",
    "\n",
    "\n",
    "First, we download pre-trained weights for the [GPT2 model by OpenAI](https://openai.com/research/better-language-models) - a prominent model from 2019.\n",
    "\n",
    "\n",
    "\n",
    "Idea & code by: Ilya Beletsky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-06T14:53:39.301198Z",
     "iopub.status.busy": "2024-04-06T14:53:39.301198Z",
     "iopub.status.idle": "2024-04-06T14:54:00.250241Z",
     "shell.execute_reply": "2024-04-06T14:54:00.249244Z",
     "shell.execute_reply.started": "2024-04-06T14:53:39.301198Z"
    },
    "id": "vOcK0lGTGqol",
    "outputId": "131fbc38-d4af-4e3b-b87b-f4c1b15d3162"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415f7f9e3ee94e429083be6377a0ecad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zenfo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\zenfo\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: ['h.0.attn.c_attn.bias', 'h.0.attn.c_attn.weight', 'h.0.attn.c_proj.bias', 'h.0.attn.c_proj.weight', 'h.0.ln_1.bias', 'h.0.ln_1.weight', 'h.0.ln_2.bias', 'h.0.ln_2.weight', 'h.0.mlp.c_fc.bias', 'h.0.mlp.c_fc.weight', 'h.0.mlp.c_proj.bias', 'h.0.mlp.c_proj.weight', 'h.1.attn.c_attn.bias', 'h.1.attn.c_attn.weight', 'h.1. ...\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "state_dict = torch.load(hf_hub_download(\"gpt2\", filename=\"pytorch_model.bin\"))\n",
    "for key, value in tuple(state_dict.items()):\n",
    "    if key.startswith('h.') and key.endswith('.weight') and value.ndim == 2:\n",
    "        value.transpose_(1, 0)  # <-- for compatibility with modern PyTorch modules\n",
    "    if key.startswith('h.') and key.endswith('.attn.bias') and value.ndim == 4:\n",
    "        state_dict.pop(key)  # <-- triangular binar masks, not needed in this code\n",
    "\n",
    "print('Weights:', repr(sorted(state_dict.keys()))[:320], '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mr0SUtQnGqom"
   },
   "source": [
    "In the next few cells, we shall implement the model layer by layer to make use of those weights.\n",
    "\n",
    "As you might recall, transformers contain two main layer types: attention and fully-connected layers.\n",
    "\n",
    "The fully connected layers are by far easier to understand, so we shall begin there:\n",
    "\n",
    "Please implement fully-connected layer __without residual or layer normalization__ (we'll add those in a bit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T15:34:04.835512Z",
     "iopub.status.busy": "2024-04-06T15:34:04.835512Z",
     "iopub.status.idle": "2024-04-06T15:34:04.843490Z",
     "shell.execute_reply": "2024-04-06T15:34:04.843490Z",
     "shell.execute_reply.started": "2024-04-06T15:34:04.835512Z"
    },
    "id": "3Rh-6DX9Gqom"
   },
   "outputs": [],
   "source": [
    "class GeLUThatWasUsedInGPT2(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * x ** 3)))\n",
    "\n",
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self, dim: int):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(dim, 4  * dim)\n",
    "        self.gelu = GeLUThatWasUsedInGPT2()\n",
    "        self.c_proj = nn.Linear(4 * dim, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape = [batch_size, seq_length, dim]\n",
    "        # <YOUR CODE HERE - COMPUTE LAYER OUTPUTS>\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        return  x #<MLP OUTPUTS>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSVGKnHBGqom"
   },
   "source": [
    "Now, let's test that it works with GPT-2 weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T15:34:05.665229Z",
     "iopub.status.busy": "2024-04-06T15:34:05.665229Z",
     "iopub.status.idle": "2024-04-06T15:34:05.802411Z",
     "shell.execute_reply": "2024-04-06T15:34:05.802411Z",
     "shell.execute_reply.started": "2024-04-06T15:34:05.665229Z"
    },
    "id": "CoWjZwZkGqom"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems legit!\n"
     ]
    }
   ],
   "source": [
    "mlp = FullyConnected(dim=768)\n",
    "mlp.load_state_dict({'c_fc.weight': state_dict['h.0.mlp.c_fc.weight'],\n",
    "                     'c_fc.bias': state_dict['h.0.mlp.c_fc.bias'],\n",
    "                     'c_proj.weight': state_dict['h.0.mlp.c_proj.weight'],\n",
    "                     'c_proj.bias': state_dict['h.0.mlp.c_proj.bias']})\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "x = torch.randn(1, 2, 768)  # [batch_size, sequence_length, dim]\n",
    "checksum = torch.sum(mlp(x) * x)\n",
    "assert abs(checksum.item() - 1282.3315) < 0.1, \"layer outputs do not match reference\"\n",
    "assert torch.allclose(mlp(x[:, (1, 0), :])[:, (1, 0), :], mlp(x)), \"mlp must be permutation-invariant\"\n",
    "print(\"Seems legit!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbfCevRwGqom"
   },
   "source": [
    "Now, let's get to attention layers.\n",
    "\n",
    "Since GPT-2 needs to generate text from left to right, each generated token can only attend to tokens on the left (and itself). This kid of attention is called \"Masked\" self-attention, because it hides tokens to the right.\n",
    "\n",
    "As before, please implement masked self-attention __without layernorm or residual connections.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T15:34:06.572420Z",
     "iopub.status.busy": "2024-04-06T15:34:06.572420Z",
     "iopub.status.idle": "2024-04-06T15:34:06.587381Z",
     "shell.execute_reply": "2024-04-06T15:34:06.586383Z",
     "shell.execute_reply.started": "2024-04-06T15:34:06.572420Z"
    },
    "id": "T6j7M4hLGqon"
   },
   "outputs": [],
   "source": [
    "class MaskedSelfAttention(nn.Module):\n",
    "    def __init__(self, dim: int, num_heads: int):\n",
    "        super().__init__()\n",
    "        self.c_attn = nn.Linear(dim, dim * 3)  # query + key + value, combined\n",
    "        self.c_proj = nn.Linear(dim, dim)  # output projection\n",
    "        self.dim, self.num_heads = dim, num_heads\n",
    "        self.head_size = dim // num_heads\n",
    "\n",
    "    def forward(self, x):\n",
    "        q, k, v = self.c_attn(x).split(dim=-1, split_size=self.dim)\n",
    "        assert q.shape == k.shape == v.shape == x.shape, \"q, k and v must have the same shape as x\"\n",
    "\n",
    "\n",
    "        # Note: this is an inefficient implementation that uses a for-loop.\n",
    "        # To get the full grade during homework, please re-implement this code:\n",
    "        # 1) do not use for-loops (or other loops). Compute everything in parallel with vectorized operations\n",
    "        # 2) do not use F.scaled_dot_product_attention - write your own attention code using basic PyTorch ops\n",
    "        head_outputs = []\n",
    "        for head_index in range(self.num_heads):\n",
    "            head_selector = range(self.head_size * head_index, self.head_size * (head_index + 1))\n",
    "\n",
    "            head_queries = q[..., head_selector]\n",
    "            head_keys = k[..., head_selector]\n",
    "            head_values = v[..., head_selector]\n",
    "\n",
    "            single_head_output = F.scaled_dot_product_attention(\n",
    "                head_queries, head_keys, head_values,\n",
    "                is_causal=True)\n",
    "            # docs: https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html\n",
    "            head_outputs.append(single_head_output)\n",
    "\n",
    "        combined_head_outputs = torch.cat(head_outputs, dim=-1)\n",
    "        return self.c_proj(combined_head_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umZpcpIkJva7"
   },
   "source": [
    "Test that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-06T15:34:07.591628Z",
     "iopub.status.busy": "2024-04-06T15:34:07.590605Z",
     "iopub.status.idle": "2024-04-06T15:34:07.689341Z",
     "shell.execute_reply": "2024-04-06T15:34:07.688357Z",
     "shell.execute_reply.started": "2024-04-06T15:34:07.590605Z"
    },
    "id": "tg5Oj_PPM6hj",
    "outputId": "ebeddb50-d805-47ae-cc3a-4d68d900b3a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It works!\n"
     ]
    }
   ],
   "source": [
    "attn = MaskedSelfAttention(dim=768, num_heads=12)\n",
    "attn.load_state_dict({'c_attn.weight': state_dict['h.0.attn.c_attn.weight'],\n",
    "                      'c_attn.bias': state_dict['h.0.attn.c_attn.bias'],\n",
    "                      'c_proj.weight': state_dict['h.0.attn.c_proj.weight'],\n",
    "                      'c_proj.bias': state_dict['h.0.attn.c_proj.bias']})\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "x = torch.randn(1, 10, 768)  # [batch_size, sequence_length, dim]\n",
    "checksum = torch.sum(attn(x) * x)\n",
    "assert abs(checksum.item() - 2703.6772) < 0.1, \"layer outputs do not match reference\"\n",
    "assert not torch.allclose(attn(x[:, (1, 0), :])[:, (1, 0), :], attn(x[:, (0, 1), :])), \"masked attention must *not* be permutation-invariant\"\n",
    "print(\"It works!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rn6tgTHzOK4l"
   },
   "source": [
    "We can now combine attention and MLP to build the full transformer layer:\n",
    "\n",
    "![img](https://i.imgur.com/1sq2vHO.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T15:34:08.489653Z",
     "iopub.status.busy": "2024-04-06T15:34:08.489653Z",
     "iopub.status.idle": "2024-04-06T15:34:08.504589Z",
     "shell.execute_reply": "2024-04-06T15:34:08.503626Z",
     "shell.execute_reply.started": "2024-04-06T15:34:08.489653Z"
    },
    "id": "p3AH7YQvRpvU"
   },
   "outputs": [],
   "source": [
    "class TransformerLayer(nn.Module):\n",
    "    def __init__(self, dim: int, num_heads: int):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(dim)\n",
    "        self.attn = MaskedSelfAttention(dim, num_heads)\n",
    "        self.ln_2 = nn.LayerNorm(dim)\n",
    "        self.mlp = FullyConnected(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        rx1 = self.attn(self.ln_1(x)) + x\n",
    "        rx2 = self.mlp(self.ln_2(rx1)) + rx1\n",
    "        # x  += rx2\n",
    "        # <YOUR CODE - apply attention, mlp and layer normalization as shown in figure above>\n",
    "        return rx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-06T15:34:08.993755Z",
     "iopub.status.busy": "2024-04-06T15:34:08.993755Z",
     "iopub.status.idle": "2024-04-06T15:34:09.096524Z",
     "shell.execute_reply": "2024-04-06T15:34:09.096524Z",
     "shell.execute_reply.started": "2024-04-06T15:34:08.993755Z"
    },
    "id": "Qzo_QeFVSNZa",
    "outputId": "15613968-b4d7-4391-dfff-3b490951a125"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good job!\n"
     ]
    }
   ],
   "source": [
    "layer = TransformerLayer(dim=768, num_heads=12)\n",
    "layer.load_state_dict({k[5:]: v for k, v in state_dict.items() if k.startswith('h.10.')})\n",
    "assert abs(torch.sum(layer(x) * x).item() - 9874.7383) < 0.1\n",
    "print(\"Good job!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T15:34:15.847502Z",
     "iopub.status.busy": "2024-04-06T15:34:15.845508Z",
     "iopub.status.idle": "2024-04-06T15:34:15.875429Z",
     "shell.execute_reply": "2024-04-06T15:34:15.873437Z",
     "shell.execute_reply.started": "2024-04-06T15:34:15.846522Z"
    },
    "id": "Mbqw9iuaSrYy"
   },
   "outputs": [],
   "source": [
    "class GPT2(nn.Module):\n",
    "    def __init__(self, vocab_size: int, dim: int, num_heads: int, num_layers: int, max_position_embeddings: int = 1024):\n",
    "        super().__init__()\n",
    "        self.wte = nn.Embedding(vocab_size, dim)  # token embeddings\n",
    "        self.wpe = nn.Embedding(max_position_embeddings, dim)  # position embeddings\n",
    "        self.ln_f = nn.LayerNorm(dim)   # final layer norm - goes after all transformer layers, but before logits\n",
    "\n",
    "        self.h = nn.Sequential(*(TransformerLayer(dim, num_heads) for layer in range(num_layers)))\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        # input_ids.shape: [batch_size, sequence_length], int64 token ids\n",
    "        position_ids = torch.arange(input_ids.shape[1], device=input_ids.device).unsqueeze(0)\n",
    "\n",
    "        token_embeddings = self.wte(input_ids)\n",
    "        position_embeddings = self.wpe(position_ids)\n",
    "        full_embeddings = token_embeddings + position_embeddings\n",
    "\n",
    "        transformer_output = self.h(full_embeddings)\n",
    "        transformer_output_ln = self.ln_f(transformer_output)\n",
    "\n",
    "        # final layer: we predict logits by re-using token embeddings as linear weights\n",
    "        output_logits = transformer_output_ln @ self.wte.weight.T\n",
    "        return output_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T15:34:18.442189Z",
     "iopub.status.busy": "2024-04-06T15:34:18.442189Z",
     "iopub.status.idle": "2024-04-06T15:34:25.706561Z",
     "shell.execute_reply": "2024-04-06T15:34:25.697585Z",
     "shell.execute_reply.started": "2024-04-06T15:34:18.442189Z"
    },
    "id": "p0m8jt66aDIh"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b6ba2833e04e0d96f6dbcced1aae0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338f09cf0595451ca6077a1c7a4f8ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b203afcf0712418095f3963181b8c594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9f617a0a174bac9bd416badf37c841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24209b18fd749a7be9a9601ce08c2e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  look\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2', add_prefix_space=True)\n",
    "model = GPT2(vocab_size=50257, dim=768, num_heads=12, num_layers=12)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "input_ids = tokenizer(\"A quick\", return_tensors='pt')['input_ids']\n",
    "\n",
    "predicted_logits = model(input_ids)\n",
    "most_likely_token_id = predicted_logits[:, -1].argmax().item()\n",
    "\n",
    "print(\"Prediction:\", tokenizer.decode(most_likely_token_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-06T15:40:50.484210Z",
     "iopub.status.busy": "2024-04-06T15:40:50.481211Z",
     "iopub.status.idle": "2024-04-06T15:47:57.789149Z",
     "shell.execute_reply": "2024-04-06T15:47:57.787211Z",
     "shell.execute_reply.started": "2024-04-06T15:40:50.484210Z"
    },
    "id": "R8ql3Lo7dXZ2",
    "outputId": "8db86d13-d16b-4f97-db87-0385c0d91426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Fermi paradox  is also a click on. Obviously I'm going to be one of those people to suggest disparaging things about\n",
      " coincidence in our future, because it causes my comfort level to decline. When you question my comfort level because of a\n",
      " digital camera I get answering, \"If you can click on this though Metropolitan you can watch 'em, but that's us.\" This goes\n",
      " against everything I've ever thought about probability. But what happens if you're better able to cut through that fear and\n",
      " ask, \"But what about this? It's just a couple of Boys Club salts? What about this?\" I think we could just associate the various\n",
      " strains of probability with the 19th century French mystery of money and moneyedness and trickery. As a relatively easy thing\n",
      " to imagine that would result in a plane crash or an earthquake, and knowing it, you'd only visualize something that you like\n",
      ". So I'm going to do a little bit of understanding then but I never want to experience what we're seeing right now.\n",
      "We learn\n",
      " a lot by stare. When a spider shows us what's going on at this place, we notice a spider eyes and (a stress response) we\n",
      " don't see them. There's a reaction between those two and the potential points these spiders will act on – probability and\n",
      " anxiety exchanges. (Face the approach. Presentment is escalating.) But alternative methods because without looking we can\n",
      " see them because no face has ever referenced them. VT research has shown that to be unrealistic, it might be cool, but leaving\n",
      " out people can cause a lot of problems in your day to day life.\n",
      "Given this, it might be an interesting to see how Harry Gin\n",
      "stead seems to have adopted \"exciting as ideal\" positive expectation. A more blunt open mind would let us cultivate the notion\n",
      " of creating new good and foundality, isn't an outcome that goes without saying. And not only can any positive experience\n",
      " be made positive by relying on it but the positive of doing it. It is time for a history about expectation and done expectations\n",
      " as a skeptical form of skepticism.\n",
      "Still, one thing I want to emphasize is that psychological problems tend to be common\n",
      " with life because we tend to frustrate our natural they are causes a host of counterintuitive and potentially farcical problems\n",
      ". And I'd say that what's interesting about psychology is that we don't think about these things too often, because when we\n",
      "'re in those episodes we normally think of my brain as a kind of rubber glove"
     ]
    }
   ],
   "source": [
    "text = \"The Fermi paradox \"\n",
    "tokens = tokenizer.encode(text)\n",
    "print(end=tokenizer.decode(tokens))\n",
    "line_length = len(tokenizer.decode(tokens))\n",
    "\n",
    "for i in range(500):\n",
    "    # Predict logits with your model\n",
    "    with torch.no_grad():\n",
    "        logits = model(torch.as_tensor([tokens]))\n",
    "\n",
    "    # Sample with probabilities\n",
    "    p_next = torch.softmax(logits[0, -1, :], dim=-1).data.cpu().numpy()\n",
    "    next_token_index = np.random.choice(len(p_next), p=p_next)\n",
    "\n",
    "    tokens.append(int(next_token_index))\n",
    "    print(end=tokenizer.decode(tokens[-1]))\n",
    "    line_length += len(tokenizer.decode(tokens[-1]))\n",
    "    if line_length > 120:\n",
    "      line_length = 0\n",
    "      print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3NJ0ocgGqop"
   },
   "source": [
    "__Reminder:__ after class, please go to `MaskedSelfAttention.forward` above and finish the job!\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### Here's how you can do the same with transformers library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTOHu124Gqop",
    "outputId": "5bb38785-a7d9-47e1-a887-c03634945c0b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated continuation:  The Fermi paradox  (with its paradoxical consequences which, if any, may also be taken to be the paradox of the Big Bang. If an explosion can only happen after the collapse of the matter in one of three states  or after the collapse of a\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2', add_prefix_space=True)\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "print('Generated text:', tokenizer.decode(\n",
    "    model.generate(\n",
    "        **tokenizer(\"The Fermi paradox \", return_tensors='pt'),\n",
    "        do_sample=True, max_new_tokens=50\n",
    "    ).flatten().numpy()\n",
    "))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "15227ca6cc5a4d219e0113da09926da4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b194af3033342b0b04dc12b3e055ff2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b76512711884ffb81d3c3505b8fd137": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e463fce356b46859493cbd975163ef1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fd2361180bd49aa8e2012a5e379d0c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6099e17176dd4eef829ac7c45badc9e2",
      "placeholder": "​",
      "style": "IPY_MODEL_7ea9a125c76543419007fd5083ed63cd",
      "value": " 629/629 [00:00&lt;00:00, 12.4kB/s]"
     }
    },
    "237d34743ee64428a9d22ee51e0423f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f36db95f6fb4b4687c7130fc23c4348",
      "placeholder": "​",
      "style": "IPY_MODEL_82a35a7ae5e441a1b66534a3eab5e765",
      "value": " 232k/232k [00:00&lt;00:00, 3.06MB/s]"
     }
    },
    "2f53a3d1d0f44192beeb6ed8d40e762f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "391b8f44109544328617fbc3a3c3b9fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3af4702b95484b8cabd891b18ffc71b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3f4eae6f79054676976f87b9524c4cf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b194af3033342b0b04dc12b3e055ff2",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_391b8f44109544328617fbc3a3c3b9fc",
      "value": 231508
     }
    },
    "48c3bc239f16407bbba2d36ac6e5aaae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ecb5a9efc3c42dd8faf4af9424ad5cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f084bbe71bb433ba0e7ee50fccb71cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5694548560b548dabed4b111766da60e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48c3bc239f16407bbba2d36ac6e5aaae",
      "placeholder": "​",
      "style": "IPY_MODEL_5c87b856ffeb4c1dbf2d4637065d26ef",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "5c87b856ffeb4c1dbf2d4637065d26ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5cff2bc12fec494e9e19b8a956186df6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_787781c894bd46c6990f2513d9f2c79c",
       "IPY_MODEL_3f4eae6f79054676976f87b9524c4cf5",
       "IPY_MODEL_237d34743ee64428a9d22ee51e0423f3"
      ],
      "layout": "IPY_MODEL_b095428dcb8a4408854f854de54d5692"
     }
    },
    "6099e17176dd4eef829ac7c45badc9e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60e971374e5448d08e9698a5594ff60a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c8113bb76024debaf3256431cbefe35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f36db95f6fb4b4687c7130fc23c4348": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7213248ebe1f4e28a00a93eb33169170": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d71a81e25f5b4f88b8361c62e2ab9f44",
      "placeholder": "​",
      "style": "IPY_MODEL_4f084bbe71bb433ba0e7ee50fccb71cc",
      "value": " 48.0/48.0 [00:00&lt;00:00, 1.58kB/s]"
     }
    },
    "73d8ad019f044a6998e81273a922745a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77441a81d25c40819ae5af99ad70f3c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "787781c894bd46c6990f2513d9f2c79c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b76512711884ffb81d3c3505b8fd137",
      "placeholder": "​",
      "style": "IPY_MODEL_2f53a3d1d0f44192beeb6ed8d40e762f",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "7ea9a125c76543419007fd5083ed63cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7eb0bf256b8d4975b0615aa96f00bbe1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7fceb5ec7dec415a9dfcd4261aeb4a3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbbe93e1d4a5493782b7a246f3cb1760",
      "max": 629,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c3e31f6d90a84af08ee33023be184849",
      "value": 629
     }
    },
    "82a35a7ae5e441a1b66534a3eab5e765": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8578b4d2279f40dc846fcdfc2df55742": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73d8ad019f044a6998e81273a922745a",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a445a35355424cb0b4c7abf3d4e6f32d",
      "value": 48
     }
    },
    "a445a35355424cb0b4c7abf3d4e6f32d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ab6d124394214415a2580983c88bbb11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60e971374e5448d08e9698a5594ff60a",
      "placeholder": "​",
      "style": "IPY_MODEL_6c8113bb76024debaf3256431cbefe35",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "b095428dcb8a4408854f854de54d5692": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1497c0d7c3b4c04a91302a2cbc96db1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2786e8af69e490cba5048fca7a0a51e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f07e54fd856f4efc99bedb44abcece1b",
       "IPY_MODEL_e0d2ca01fd7042a88a5493323a61409c",
       "IPY_MODEL_e07d888d412d43f8ac4cc5285de07772"
      ],
      "layout": "IPY_MODEL_15227ca6cc5a4d219e0113da09926da4"
     }
    },
    "c3e31f6d90a84af08ee33023be184849": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cf83aaa31a1a47419db2127456beae69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d71a81e25f5b4f88b8361c62e2ab9f44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e07d888d412d43f8ac4cc5285de07772": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9210c257b8a4091b86123271c8a5486",
      "placeholder": "​",
      "style": "IPY_MODEL_7eb0bf256b8d4975b0615aa96f00bbe1",
      "value": " 268M/268M [00:01&lt;00:00, 172MB/s]"
     }
    },
    "e0d2ca01fd7042a88a5493323a61409c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ecb5a9efc3c42dd8faf4af9424ad5cf",
      "max": 267832558,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3af4702b95484b8cabd891b18ffc71b1",
      "value": 267832558
     }
    },
    "e85584c419aa445285eecb482778c7ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5694548560b548dabed4b111766da60e",
       "IPY_MODEL_7fceb5ec7dec415a9dfcd4261aeb4a3d",
       "IPY_MODEL_1fd2361180bd49aa8e2012a5e379d0c1"
      ],
      "layout": "IPY_MODEL_77441a81d25c40819ae5af99ad70f3c8"
     }
    },
    "e9210c257b8a4091b86123271c8a5486": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f07e54fd856f4efc99bedb44abcece1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf83aaa31a1a47419db2127456beae69",
      "placeholder": "​",
      "style": "IPY_MODEL_1e463fce356b46859493cbd975163ef1",
      "value": "Downloading model.safetensors: 100%"
     }
    },
    "fbbe93e1d4a5493782b7a246f3cb1760": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc132bfb7d6447ad9900af7b80806aa1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ab6d124394214415a2580983c88bbb11",
       "IPY_MODEL_8578b4d2279f40dc846fcdfc2df55742",
       "IPY_MODEL_7213248ebe1f4e28a00a93eb33169170"
      ],
      "layout": "IPY_MODEL_b1497c0d7c3b4c04a91302a2cbc96db1"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
